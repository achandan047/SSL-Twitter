{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=1\n",
      "env: CUDA_LAUNCH_BLOCKING=1\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=1\n",
    "%env CUDA_LAUNCH_BLOCKING=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "import os\n",
    "# from datetime import datetime\n",
    "from os import path\n",
    "from tqdm.auto import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models\n",
    "import torch\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "import torch.nn as nn\n",
    "from transformers import WEIGHTS_NAME, CONFIG_NAME, AdamW\n",
    "from transformers import get_linear_schedule_with_warmup, get_constant_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "import torch.optim as optim\n",
    "\n",
    "# Evaluation\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import Config\n",
    "from dataset import *\n",
    "\n",
    "from semisupervised.model import (\n",
    "    SequenceRegressionModel, \n",
    "    MODEL_CLASSES\n",
    ")\n",
    "from semisupervised.utils import (\n",
    "    evaluate, \n",
    "    evaluate_metrics, \n",
    "    evaluate_test_metrics,\n",
    "    save_metrics, \n",
    "    load_metrics, \n",
    "    predict_ensemble\n",
    ")\n",
    "\n",
    "try:\n",
    "    from torch.utils.tensorboard import SummaryWriter\n",
    "except ImportError:\n",
    "    from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dateTimeObj = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=32, early_stopping_thresh=0.1, ens_iter=2, eval_bs=200, label='Information_discrete', learning_rate=2e-05, model_path='models/hard_Information_discrete_Normalized_distil', normalize_label=True, num_epochs=10, thresh=0.9)\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--num_epochs', type=int, default=10)\n",
    "parser.add_argument('--learning_rate', type=float, default=2e-5)\n",
    "parser.add_argument('--batch_size', type=int, default=32)\n",
    "parser.add_argument('--ens_iter', type=int, default=2)\n",
    "parser.add_argument('--thresh', type=float, default=0.9)\n",
    "parser.add_argument('--label', type=str, default='Information_discrete')\n",
    "parser.add_argument('--normalize_label', type=bool, default=True)\n",
    "parser.add_argument('--early_stopping_thresh', type=float, default=0.1)\n",
    "parser.add_argument('--model_path', type=str, default='models/hard_Information_discrete_Normalized_distil')\n",
    "parser.add_argument('--eval_bs', type=int, default=200)\n",
    "\n",
    "# args = parser.parse_args()\n",
    "args = parser.parse_args(args=[])\n",
    "print (args)\n",
    "\n",
    "if not path.isdir(args.model_path):\n",
    "    os.mkdir(args.model_path)\n",
    "\n",
    "import json\n",
    "with open(args.model_path + '/args.txt', 'w') as f:\n",
    "    json.dump(args.__dict__, f, indent=2)\n",
    "    \n",
    "config = Config(dataset=\"twitter\", model_home=args.model_path, do_ensemble=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,\n",
    "          train_loader,\n",
    "          valid_loader,\n",
    "          iteration,\n",
    "          model_path,\n",
    "          tb_writer,\n",
    "          learning_rate,\n",
    "          num_epochs = 1,\n",
    "          early_stopping_thresh=None):\n",
    "    \n",
    "    best_valid_loss = float(\"Inf\")\n",
    "    eval_every = len(train_loader) // 6\n",
    "    \n",
    "    t_total = len(train_loader) * num_epochs\n",
    "    \n",
    "    adam_epsilon = 1e-8\n",
    "    max_grad_norm = 1.0\n",
    "    \n",
    "    # Prepare optimizer and schedule (linear warmup and decay)\n",
    "    no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "    optimizer_grouped_parameters = [\n",
    "        {\n",
    "            \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "            \"weight_decay\": 0.0,\n",
    "        },\n",
    "        {\"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0},\n",
    "    ]\n",
    "    optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate, eps=adam_epsilon)\n",
    "    scheduler = get_constant_schedule_with_warmup(\n",
    "        optimizer, num_warmup_steps=0\n",
    "    )\n",
    "    \n",
    "    weights_path = path.join(model_path, WEIGHTS_NAME)\n",
    "    config_path = path.join(model_path, CONFIG_NAME)\n",
    "    metrics_path = path.join(model_path, 'metrics.pt')\n",
    "    plot_path = path.join(model_path, 'plot_losses.png')\n",
    "\n",
    "    average_train_loss = 0.0\n",
    "    average_valid_loss = 0.0\n",
    "\n",
    "    # initialize running values\n",
    "    running_loss = 0.0\n",
    "    valid_running_loss = 0.0\n",
    "    global_step = 0\n",
    "    train_loss_list = []\n",
    "    valid_loss_list = []\n",
    "    global_steps_list = []\n",
    "    \n",
    "    # training loop\n",
    "    model.train()\n",
    "    for epoch in trange(num_epochs, desc=\"Epoch\"):\n",
    "        for batch in tqdm(train_loader, desc=\"Train\", leave=False):\n",
    "            comments = batch[0].type(torch.LongTensor)\n",
    "            masks = batch[1].type(torch.LongTensor)\n",
    "            labels = batch[2].type(torch.FloatTensor)\n",
    "\n",
    "            comments = comments.to(device)\n",
    "            masks = masks.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(input_ids=comments, attention_mask=masks, labels=labels)\n",
    "            loss, logits = outputs[:2]\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            # update running values\n",
    "            running_loss += loss.item()\n",
    "            global_step += 1\n",
    "\n",
    "            # evaluation step\n",
    "            if global_step % eval_every == 0:\n",
    "                model.eval()\n",
    "                with torch.no_grad():                    \n",
    "                    # validation loop\n",
    "                    for batch in tqdm(valid_loader, desc=\"Val\", leave=False):\n",
    "                        comments = batch[0].type(torch.LongTensor)\n",
    "                        masks = batch[1].type(torch.LongTensor)\n",
    "                        labels = batch[2].type(torch.FloatTensor)\n",
    "                        \n",
    "                        comments = comments.to(device)\n",
    "                        masks = masks.to(device)\n",
    "                        labels = labels.to(device)\n",
    "                        \n",
    "                        outputs = model(input_ids=comments, attention_mask=masks, labels=labels)\n",
    "                        loss, logits = outputs[:2]\n",
    "                        \n",
    "                        valid_running_loss += loss.item()\n",
    "                    \n",
    "                    val_output = evaluate_metrics(model, valid_loader, show=False)\n",
    "                    tb_writer.add_scalar(\"rmse_val\", val_output[1], global_step)\n",
    "                    tb_writer.add_scalar(\"val_acc/0.5\", val_output[2], global_step)\n",
    "                    tb_writer.add_scalar(\"val_acc/1.0\", val_output[3], global_step)\n",
    "\n",
    "                # evaluation\n",
    "                average_train_loss = running_loss / eval_every\n",
    "                average_valid_loss = valid_running_loss / len(valid_loader)\n",
    "                train_loss_list.append(average_train_loss)\n",
    "                valid_loss_list.append(average_valid_loss)\n",
    "                global_steps_list.append(global_step)\n",
    "                \n",
    "                tb_writer.add_scalar(\"Loss/Train\", average_train_loss, global_step)\n",
    "                tb_writer.add_scalar(\"Loss/Val\", average_valid_loss, global_step)\n",
    "                tb_writer.add_scalar(\"lr\", scheduler.get_lr()[0], global_step)\n",
    "                \n",
    "                # resetting running values\n",
    "                running_loss = 0.0                \n",
    "                valid_running_loss = 0.0\n",
    "                model.train()\n",
    "\n",
    "                # print progress\n",
    "#                 print('\\nEpoch [{}/{}], Step [{}/{}], Train Loss: {:.4f}, Valid Loss: {:.4f}'\n",
    "#                       .format(epoch+1, num_epochs, global_step, num_epochs*len(train_loader),\n",
    "#                               average_train_loss, average_valid_loss))\n",
    "                \n",
    "                # checkpoint\n",
    "                if best_valid_loss > average_valid_loss:\n",
    "                    best_valid_loss = average_valid_loss\n",
    "                    # model.save_pretrained(model_path)\n",
    "                    model.config.save_pretrained(model_path)\n",
    "                    torch.save(model.state_dict(), weights_path)\n",
    "                    save_metrics(metrics_path, train_loss_list, valid_loss_list, global_steps_list)\n",
    "\n",
    "                if early_stopping_thresh is not None:\n",
    "                    if average_valid_loss - average_train_loss > args.early_stopping_thresh:\n",
    "                        break\n",
    "\n",
    "        if early_stopping_thresh is not None:\n",
    "            if average_valid_loss - average_train_loss > args.early_stopping_thresh:\n",
    "                print (\"Early stopping\")\n",
    "                break\n",
    "    \n",
    "    save_metrics(metrics_path, train_loss_list, valid_loss_list, global_steps_list)\n",
    "    \n",
    "#     train_loss_list, valid_loss_list, global_steps_list = load_metrics(metrics_path)\n",
    "#     plt.plot(global_steps_list[1:], train_loss_list[1:], label='Train')\n",
    "#     plt.plot(global_steps_list[1:], valid_loss_list[1:], label='Valid')\n",
    "#     plt.xlabel('Global Steps')\n",
    "#     plt.ylabel('Loss')\n",
    "#     plt.legend()\n",
    "#     plt.savefig(plot_path)\n",
    "#     plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokenizer(model_name, init):\n",
    "    _, _, tokenizer_class, options_name = MODEL_CLASSES[model_name]\n",
    "    \n",
    "    if init:\n",
    "        model_path = options_name\n",
    "    else:\n",
    "        model_path = path.join(args.model_path, model_name)\n",
    "    \n",
    "    print (\"Loading tokenizer from {}\".format(model_path))\n",
    "    return tokenizer_class.from_pretrained(model_path)\n",
    "\n",
    "\n",
    "def save_tokenizer(tokenizer, model_name):\n",
    "    model_path = path.join(args.model_path, model_name)\n",
    "    tokenizer.save_pretrained(model_path)\n",
    "    print (\"Saving Tokenizer in {}\".format(model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================\n",
      "Model bert-base1\n",
      "Loading tokenizer from models/hard_Information_discrete_Normalized_distil/bert-base1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Tokenize Train'), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='2…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Tokenize Val'), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20p…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Tokenize Test'), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Tokenize unlabeled'), FloatProgress(value=1.0, bar_style='info', layout=Layout(widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model run 0 already trained\n",
      "\n",
      "Test set evaluation\n",
      "RMSE: 0.5230282540084185\n",
      "[-0.5, 0.5] range accuracy: 72.6\n",
      "[-1.0, 1.0] range accuracy: 76.2\n",
      "\n",
      "Unlabeled set pseudo-labelling\n",
      "Model:bert-base1 loading labels for unlabeled data\n",
      "==========================================\n",
      "==========================================\n",
      "Model roberta-base1\n",
      "Loading tokenizer from models/hard_Information_discrete_Normalized_distil/roberta-base1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Tokenize Train'), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='2…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Tokenize Val'), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20p…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Tokenize Test'), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Tokenize unlabeled'), FloatProgress(value=1.0, bar_style='info', layout=Layout(widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model run 0 already trained\n",
      "\n",
      "Test set evaluation\n",
      "RMSE: 0.5417761001254551\n",
      "[-0.5, 0.5] range accuracy: 71.8\n",
      "[-1.0, 1.0] range accuracy: 74.7\n",
      "\n",
      "Unlabeled set pseudo-labelling\n",
      "Model:roberta-base1 loading labels for unlabeled data\n",
      "==========================================\n",
      "==========================================\n",
      "==========================================\n",
      "RMSE: 0.8927865323884048\n",
      "[-0.5, 0.5] range accuracy: 72.5\n",
      "[-1.0, 1.0] range accuracy: 75.7\n",
      "Ensemble iteration 0\n",
      "Total samples 30000\n",
      "Filtering samples by ensemble variance\n",
      "Filtered samples based on ensemble variances are 3201\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================\n",
      "==========================================\n",
      "Model bert-base1\n",
      "Loading tokenizer from models/hard_Information_discrete_Normalized_distil/bert-base1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Tokenize Train'), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='2…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Tokenize Val'), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20p…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Tokenize Test'), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Tokenize unlabeled'), FloatProgress(value=1.0, bar_style='info', layout=Layout(widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/Transformers/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   5150\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5151\u001b[0;31m             \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5152\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Transformers/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mname\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    489\u001b[0m         \"\"\"\n\u001b[0;32m--> 490\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Transformers/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5134\u001b[0m         ):\n\u001b[0;32m-> 5135\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute '_name'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-4885f248ae57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m                                                                        \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                                                                        \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                                                                        iteration=iteration) \n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mcurr_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miteration_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Disclosure/SelfDisclosure/dataset.py\u001b[0m in \u001b[0;36mget_dataset\u001b[0;34m(tokenizer, args, config, iteration)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;31m#     cache_file = os.path.join(config.cache_path, \"unlabeled_processed_\" + str(iteration) + \".pt\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;31m#     if config.overwrite_cache or not os.path.exists(cache_file):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m     \u001b[0mX_unlabeled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_unlabeled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munlabeled_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Tokenize unlabeled\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;31m#         torch.save((X_unlabeled, mask_unlabeled), cache_file)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;31m#     else:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Disclosure/SelfDisclosure/dataset.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(df, tokenizer, desc)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mfield\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Text\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdesc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0msent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfield\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenize_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMAX_SEQ_LEN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Transformers/lib/python3.6/site-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Transformers/lib/python3.6/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1164\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1165\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1166\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Transformers/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36miterrows\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \u001b[0mklass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor_sliced\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Transformers/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0mgeneric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Transformers/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   5149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5150\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5151\u001b[0;31m             \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5152\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5153\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for iteration in range(0, 3):\n",
    "    outputs = []\n",
    "    outputs_test = []\n",
    "    \n",
    "    for model_name in MODEL_CLASSES:\n",
    "        print (\"==========================================\")\n",
    "        print (\"Model {}\".format(model_name))\n",
    "        \n",
    "        # paths\n",
    "        model_path = path.join(args.model_path, model_name)\n",
    "        if not path.exists(model_path): \n",
    "            os.mkdir(model_path)\n",
    "        \n",
    "        iteration_path = path.join(model_path, 'run' + str(iteration))\n",
    "        \n",
    "        # tokenizer and dataset\n",
    "        try:\n",
    "            tokenizer = get_tokenizer(model_name, False)\n",
    "        except:\n",
    "            tokenizer = get_tokenizer(model_name, True)\n",
    "        \n",
    "        train_data, val_data, test_data, unlabeled_data = get_dataset(tokenizer=tokenizer,\n",
    "                                                                       args=args, \n",
    "                                                                       config=config,\n",
    "                                                                       iteration=iteration) \n",
    "        \n",
    "        curr_path = iteration_path\n",
    "\n",
    "        if path.exists(path.join(curr_path, WEIGHTS_NAME)) and not config.retrain: \n",
    "            print (\"Model run {} already trained\".format(iteration)) \n",
    "            model = SequenceRegressionModel(model_name=model_name, model_path=curr_path).to(device) \n",
    "            model.load_state_dict(torch.load(path.join(curr_path, WEIGHTS_NAME), map_location=device))\n",
    "        else:\n",
    "            print (\"Training model {} run {}\".format(model_name, iteration)) \n",
    "\n",
    "            if not path.exists(curr_path):\n",
    "                os.mkdir(curr_path) \n",
    "\n",
    "            save_tokenizer(tokenizer, model_name) \n",
    "\n",
    "            # data and iterator\n",
    "            train_iter = get_iterator(dataset=train_data, batch_size=args.batch_size, shuffle=True, weighted=True)\n",
    "            valid_iter = get_iterator(dataset=val_data, batch_size=args.eval_bs, shuffle=True, weighted=True)\n",
    "\n",
    "            # model and train\n",
    "            model = SequenceRegressionModel(model_name=model_name).to(device)\n",
    "            tb_writer = SummaryWriter(log_dir='runs/hard_normalized_distil_' + model_name + \"_\" + str(iteration))\n",
    "            train(model=model, \n",
    "                    model_path=curr_path, \n",
    "                    early_stopping_thresh=None,\n",
    "                    iteration=iteration, num_epochs=args.num_epochs,\n",
    "                    learning_rate=args.learning_rate, tb_writer=tb_writer,\n",
    "                    train_loader=train_iter, valid_loader=valid_iter)\n",
    "            tb_writer.close()\n",
    "            \n",
    "            print (\"Loading the best model from {}\".format(curr_path));\n",
    "            model = SequenceRegressionModel(model_name=model_name, model_path=curr_path).to(device) \n",
    "            model.load_state_dict(torch.load(path.join(curr_path, WEIGHTS_NAME), map_location=device))\n",
    "\n",
    "            # evaluation - validation\n",
    "            print (\"\\nValidation set evaluation\")\n",
    "            # valid_iter = get_iterator(dataset=val_data, batch_size=args.eval_bs, shuffle=False)\n",
    "            evaluate_metrics(model, valid_iter)\n",
    "\n",
    "        # evaluation - test\n",
    "        print (\"\\nTest set evaluation\")\n",
    "        test_iter = get_iterator(dataset=test_data, batch_size=args.eval_bs, shuffle=False) \n",
    "        output_test = evaluate_metrics(model, test_iter) \n",
    "        outputs_test.append(output_test[0])\n",
    "\n",
    "        # evaluate - unlabeled\n",
    "        print (\"\\nUnlabeled set pseudo-labelling\")\n",
    "        output_path = path.join(curr_path, \"output.pt\")\n",
    "        if path.exists(output_path) and not config.retrain:\n",
    "            print (\"Model:{} loading labels for unlabeled data\".format(model_name))\n",
    "            output = torch.load(output_path)\n",
    "        else:\n",
    "            unlabeled_iter = get_iterator(dataset=unlabeled_data, batch_size=args.eval_bs, shuffle=False) \n",
    "            output = evaluate(model, unlabeled_iter)\n",
    "            print (\"Model:{} saving labels for unlabeled data\".format(model_name))\n",
    "            torch.save(output, output_path)\n",
    "\n",
    "        outputs.append(output)\n",
    "    \n",
    "        print (\"==========================================\")\n",
    "    \n",
    "    print (\"==========================================\")\n",
    "    print (\"==========================================\")\n",
    "    y_test_pred, y_test_var = predict_ensemble(outputs_test)\n",
    "    evaluate_test_metrics(test_iter, y_test_pred)\n",
    "    \n",
    "    y_pred, y_var = predict_ensemble(outputs)\n",
    "    unlabeled_df = add_ensemble_data(y_pred, y_var, label=args.label, config=config, iteration=iteration)\n",
    "    \n",
    "    sns.histplot(y_test_var, bins=10, label=\"Test\")\n",
    "    sns.histplot(y_var, bins=10, label=\"Unlabeled\")\n",
    "    plt.show()\n",
    "    print (\"==========================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.8946199796846238\n",
      "[-0.5, 0.5] range accuracy: 73.0\n",
      "[-1.0, 1.0] range accuracy: 73.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_test_metrics(test_iter, [0.]*len(y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.label = 'Thoughts_discrete'\n",
    "args.model_path = 'hard_Thoughts_discrete_Normalized_distil' + args.label\n",
    "\n",
    "print (args)\n",
    "\n",
    "if not path.isdir(args.model_path):\n",
    "    os.mkdir(args.model_path)\n",
    "\n",
    "import json\n",
    "with open(args.model_path + '/args.txt', 'w') as f:\n",
    "    json.dump(args.__dict__, f, indent=2)\n",
    "    \n",
    "config = Config(dataset=\"twitter\", model_home=args.model_path, do_ensemble=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iteration in range(0, 3):\n",
    "    outputs = []\n",
    "    outputs_test = []\n",
    "    \n",
    "    for model_name in MODEL_CLASSES:\n",
    "        print (\"==========================================\")\n",
    "        print (\"Model {}\".format(model_name))\n",
    "        \n",
    "        # paths\n",
    "        model_path = path.join(args.model_path, model_name)\n",
    "        if not path.exists(model_path): \n",
    "            os.mkdir(model_path)\n",
    "        \n",
    "        iteration_path = path.join(model_path, 'run' + str(iteration))\n",
    "        \n",
    "        # tokenizer and dataset\n",
    "        try:\n",
    "            tokenizer = get_tokenizer(model_name, False)\n",
    "        except:\n",
    "            tokenizer = get_tokenizer(model_name, True)\n",
    "        \n",
    "        train_data, val_data, test_data, unlabeled_data = get_dataset(tokenizer=tokenizer,\n",
    "                                                                       args=args, \n",
    "                                                                       config=config,\n",
    "                                                                       iteration=iteration) \n",
    "        \n",
    "        curr_path = iteration_path\n",
    "\n",
    "        if path.exists(path.join(curr_path, WEIGHTS_NAME)) and not config.retrain: \n",
    "            print (\"Model run {} already trained\".format(iteration)) \n",
    "            model = SequenceRegressionModel(model_name=model_name, model_path=curr_path).to(device) \n",
    "            model.load_state_dict(torch.load(path.join(curr_path, WEIGHTS_NAME), map_location=device))\n",
    "        else:\n",
    "            print (\"Training model {} run {}\".format(model_name, iteration)) \n",
    "\n",
    "            if not path.exists(curr_path):\n",
    "                os.mkdir(curr_path) \n",
    "\n",
    "            save_tokenizer(tokenizer, model_name) \n",
    "\n",
    "            # data and iterator\n",
    "            train_iter = get_iterator(dataset=train_data, batch_size=args.batch_size, shuffle=True, weighted=True)\n",
    "            valid_iter = get_iterator(dataset=val_data, batch_size=args.eval_bs, shuffle=False)\n",
    "\n",
    "            # model and train\n",
    "            model = SequenceRegressionModel(model_name=model_name).to(device)\n",
    "            tb_writer = SummaryWriter(log_dir='runs/hard_Thoughts_normalized_distil' + model_name + \"_\" + str(iteration))\n",
    "            train(model=model, \n",
    "                    model_path=curr_path, \n",
    "                    early_stopping_thresh=None,\n",
    "                    iteration=iteration, num_epochs=args.num_epochs,\n",
    "                    learning_rate=args.learning_rate, tb_writer=tb_writer,\n",
    "                    train_loader=train_iter, valid_loader=valid_iter)\n",
    "            tb_writer.close()\n",
    "            \n",
    "            print (\"Loading the best model from {}\".format(curr_path));\n",
    "            model = SequenceRegressionModel(model_name=model_name, model_path=curr_path).to(device) \n",
    "            model.load_state_dict(torch.load(path.join(curr_path, WEIGHTS_NAME), map_location=device))\n",
    "\n",
    "            # evaluation - validation\n",
    "            print (\"\\nValidation set evaluation\")\n",
    "            # valid_iter = get_iterator(dataset=val_data, batch_size=args.eval_bs, shuffle=False)\n",
    "            evaluate_metrics(model, valid_iter)\n",
    "\n",
    "        # evaluation - test\n",
    "        print (\"\\nTest set evaluation\")\n",
    "        test_iter = get_iterator(dataset=test_data, batch_size=args.eval_bs, shuffle=False) \n",
    "        output_test = evaluate_metrics(model, test_iter) \n",
    "        outputs_test.append(output_test[0])\n",
    "\n",
    "        # evaluate - unlabeled\n",
    "        print (\"\\nUnlabeled set pseudo-labelling\")\n",
    "        output_path = path.join(curr_path, \"output.pt\")\n",
    "        if path.exists(output_path) and not config.retrain:\n",
    "            print (\"Model:{} loading labels for unlabeled data\".format(model_name))\n",
    "            output = torch.load(output_path)\n",
    "        else:\n",
    "            unlabeled_iter = get_iterator(dataset=unlabeled_data, batch_size=args.eval_bs, shuffle=False) \n",
    "            output = evaluate(model, unlabeled_iter)\n",
    "            print (\"Model:{} saving labels for unlabeled data\".format(model_name))\n",
    "            torch.save(output, output_path)\n",
    "\n",
    "        outputs.append(output)\n",
    "    \n",
    "        print (\"==========================================\")\n",
    "    \n",
    "    print (\"==========================================\")\n",
    "    print (\"==========================================\")\n",
    "    y_test_pred, y_test_var = predict_ensemble(outputs_test)\n",
    "    evaluate_test_metrics(test_iter, y_test_pred)\n",
    "    \n",
    "    y_pred, y_var = predict_ensemble(outputs)\n",
    "    unlabeled_df = add_ensemble_data(y_pred, y_var, label=args.label, config=config, iteration=iteration)\n",
    "    \n",
    "    sns.histplot(y_test_var, bins=10, label=\"Test\")\n",
    "    sns.histplot(y_var, bins=10, label=\"Unlabeled\")\n",
    "    plt.show()\n",
    "    print (\"==========================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nlp)",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
